#!/usr/bin/env python3

import argparse
import os
import sys
import time

from collections import defaultdict
from os import path
from random import shuffle
from sys import stderr, argv
from subprocess import Popen, PIPE
from shutil import copyfile

from config import configs
from cmd import run_cmd
from read_mesh_dump import open_data, MB

USE_MSTAT = True
FREQ = 127

TEST_SCRIPT = 'fragmentation.redis'

ROOT_DIR = os.getcwd()

TEST_DURATION = 10 # seconds

DELIM = '>>>>>>>>>>' # delimits different mesh dumps


def print_distribution(miniheap_lines):
    size_classes = open_data(miniheap_lines)
    sizes = sorted(size_classes.keys(), reverse=True)

    total_size = 0
    live_size = 0
    meshed_size = 0

    for size in sizes:
        spans = size_classes[size]
        total_size += sum([s.size * s.length for s in spans])
        live_size += sum([s.size * s.n_objects for s in spans])
        meshed_size += sum([s.size * s.length * (s.n_meshes - 1) for s in spans])

    print('Total heap size: %.1f MiB' % (total_size * MB,))
    print('Live  heap size: %.1f MiB' % (live_size * MB,))
    print('Meshed eap size: %.1f MiB' % (meshed_size * MB,))

    for size in sizes:
        spans = size_classes[size]
        occ = 0.0
        span_total = sum([s.size * s.length for s in spans]) or 0.0
        span_live = sum([s.size * s.n_objects for s in spans]) or 0.0
        span_meshed = sum([s.size * s.length * (s.n_meshes - 1) for s in spans]) or 0.0

        if len(spans) > 0:
            bitlen = spans[0].length
            bitcount = bitlen * len(spans)
            bits = 0
            meshes = defaultdict(int)
            counts = defaultdict(int)

            for span in spans:
                n = span.n_objects
                bits += n
                counts[n] += 1
                meshes[span.n_meshes] += 1

            occ = (float(bits) / bitcount) * 100.0

            print('\t%5d: %d spans (avg occ: %.2f) -- %.2f/%.2f (%.2f) MiB' %
                  (size, len(spans), occ, span_live * MB, span_total * MB, span_meshed * MB))

            for n in sorted(meshes.keys()):
                print('\t\t\t%d: %d' % (n, meshes[n]))

            if len(spans) > 0 and size == 256:
                for i in range(0, 16):
                    pct = float(counts[i]) / len(spans)
                    # print('\t\t%2d: %5d  %.2f' % (i, counts[i], pct))
                    print('%d\t%d\t%.3f' % (i, counts[i], pct))


def split_mesh_dump(lines):
    parts = []
    while DELIM in lines:
        i = lines.index(DELIM)
        if i > 0:
            parts.append(lines[:i])
        lines = lines[i+1:]
    if lines:
        parts.append(lines)
    return parts


# from rainbow
def make_reporter(verbosity, quiet, filelike):
    '''
    Returns a function suitible for logging use.
    '''
    if not quiet:
        def report(level, msg, *args):
            'Log if the specified severity is <= the initial verbosity.'
            if level <= verbosity:
                if len(args):
                    filelike.write(msg % args + '\n')
                else:
                    filelike.write('%s\n' % (msg, ))
    else:
        def report(level, msg, *args):
            '/dev/null logger.'
            pass

    return report


ERROR = 0
WARN = 1
INFO = 2
DEBUG = 3
log = make_reporter(WARN, False, sys.stderr)


def tool(cmd, config):
    return path.join(ROOT_DIR, 'bin', '%s-%s' % (cmd, config))


REDIS_CLI = tool('redis-cli', 'jemalloc')


def slurp(file_name):
    with open(file_name, 'r') as f:
        return f.read().strip()


def get_rss(pid, stat = 'Pss'):
    memory = slurp('/proc/%d/smaps_rollup' % pid)
    lines = memory.splitlines()
    def get_stat(stat_name):
        line = [l for l in lines if l.startswith(stat + ':')][0]
        return float(line.split()[1])/1024.0

    return get_stat(stat)


def test_perf(detailed_mesh_stats=False, enabled_configs=None, latency_stats=False, data_dir='.'):
    redis_benchmark = tool('redis-benchmark', 'jemalloc')

    for config in configs:
        if config.skip:
            continue
        if enabled_configs and config.name not in enabled_configs:
            continue

        server = tool('redis-server', config.name)
        server_cmd = run_cmd('%s redis.conf' % server)

        time.sleep(.1) # sleep for 100 ms to give server time to start

        start = time.time()

        run_cmd(redis_benchmark).join()

        end = time.time()

        duration_secs = end - start

        server_cmd.end()
        server_cmd.join()

        print('%s\t%.3f' % (config.name, duration_secs))


def getpid(name):
    getpid_cmd = run_cmd('ps -u %s' % os.getuid()).join()
    lines = getpid_cmd.stdout.decode('utf8').splitlines()
    candidates = [l for l in lines if name in l]
    if len(candidates) > 1:
        raise Exception('multiple %s running!' % name)
    elif len(candidates) == 0:
        raise Exception('couldn\'t find %s' % name)
    log(DEBUG, 'candidates: %s', (candidates,))
    return int(candidates[-1].split()[0])


def test_frag(detailed_mesh_stats=False, enabled_configs=None, latency_stats=False, data_dir='.'):
    '''
    Given a file containing commands, run them against each
    redis-server, recording memory usage.
    '''

    try:
        os.mkdir(data_dir)
    except:
        pass
    try:
        os.mkdir(path.join(data_dir, 'memory'))
    except:
        pass

    for config in configs:
        if config.skip:
            continue
        if enabled_configs and config.name not in enabled_configs:
            continue

        server = tool('redis-server', config.name)
        cmd = '%s redis.conf' % server
        if USE_MSTAT:
            mstat_results_path = path.join(data_dir, 'memory', 'ruby-frag-%s.%d.tsv' % (config.name, time.time()))
            cmd = 'mstat -o %s -freq %d -- %s' % (mstat_results_path, FREQ, cmd)

        server_cmd = run_cmd(cmd)

        start = time.time()
        time.sleep(.1) # sleep for 100 ms to give server time to start
        server_pid = getpid('redis-server')

        client = run_cmd('cat %s | %s' % (TEST_SCRIPT, REDIS_CLI)).join()

        time.sleep(.5)
        run_cmd('%s dbsize' % REDIS_CLI).join()

        rss = get_rss(server_pid)

        if 'mesh' in config.name and detailed_mesh_stats:
            run_cmd('kill -42 %d' % server_pid).join()

        if config.defrag:
            run_cmd('%s config set activedefrag yes' % REDIS_CLI).join()
            time.sleep(5) # give time to reach steady state
            run_cmd('%s config set activedefrag no' % REDIS_CLI).join()
            time.sleep(1)
            end_rss = get_rss(server_pid)
        else:
            run_cmd('%s info' % REDIS_CLI).join()
            time.sleep(5) # give time to reach steady state
            run_cmd('%s info' % REDIS_CLI).join()

        if 'mesh' in config.name and detailed_mesh_stats:
            run_cmd('kill -42 %d' % server_pid).join()
            time.sleep(1)

        elapsed = time.time() - start
        remaining = TEST_DURATION - elapsed
        if remaining > 0:
            log(DEBUG, 'sleeping %.2f sec' % remaining)
            time.sleep(remaining)
        else:
            log(DEBUG, 'aint nobody got time for sleeping')

        _rss = get_rss(server_pid, stat='Rss')
        _pss = get_rss(server_pid, stat='Pss')

        run_cmd('kill %d' % server_pid).join()
        time.sleep(.3) # give mstat a chance to finish up
        server_cmd.end()
        server_cmd.join()

        if 'mesh' in config.name and detailed_mesh_stats:
            miniheap_lines = server_cmd.stderr.decode('utf8').splitlines()
            parts = split_mesh_dump(miniheap_lines)
            log(DEBUG, 'len(parts): %d/%d/%d', len(parts), len(parts[0]), len(miniheap_lines))
            print_distribution(parts[0])
            print_distribution(parts[1])

        print('%s\t%.3f' % (config.name, _pss))


def test_fragperf(detailed_mesh_stats=False, enabled_configs=None, latency_stats=False, data_dir='.'):
    '''
    Given a file containing commands, run them against each
    redis-server, recording memory usage.
    '''

    try:
        os.mkdir(data_dir)
    except:
        pass
    try:
        os.mkdir(path.join(data_dir, 'speed'))
    except:
        pass

    with open(path.join(data_dir, 'speed', 'redis-perf.%s.tsv' % (time.time(),)), 'w') as results:
        results.write('config\tseconds\n')
        for config in configs:
            if config.skip:
                continue
            if enabled_configs and config.name not in enabled_configs:
                continue

            server = tool('redis-server', config.name)
            cmd = '%s redis.conf' % server

            if latency_stats:
                os.environ['LATALLOC_PREFIX'] = '%s/latency/%s' % (ROOT_DIR, config.name)
                os.environ['LD_PRELOAD'] = 'liblatalloc.so'
            server_cmd = run_cmd(cmd)
            if latency_stats:
                del os.environ['LATALLOC_PREFIX']
                del os.environ['LD_PRELOAD']

            start = time.time()
            time.sleep(.1) # sleep for 100 ms to give server time to start
            server_pid = getpid('redis-server')

            start = time.time()
            client = run_cmd('cat %s | %s' % (TEST_SCRIPT, REDIS_CLI)).join()
            end = time.time()

            result_row = '%s\t%.3f\n' % (config.name, end - start)
            sys.stdout.write(result_row)
            results.write(result_row)

            run_cmd('kill %d' % server_pid).join()
            time.sleep(.3) # give mstat a chance to finish up
            server_cmd.end()
            server_cmd.join()


TESTS = {
    'perf': test_perf,
    'frag': test_frag,
    'fragperf': test_fragperf,
}

# filter out perf, as it takes a long time and isn't reported in the paper
DEFAULT_TESTS = [t for t in sorted(TESTS.keys()) if t != 'perf']

def main():
    global log

    parser = argparse.ArgumentParser(description='Test redis with different allocators.')
    parser.add_argument('-v', action='store_const', const=True, help='verbose logging')
    parser.add_argument('--config', nargs='+', help='specific configs to run')
    parser.add_argument('--latency', action='store_const', const=True, default=False, help='gather latency metrics')
    parser.add_argument('--mesh-details', action='store_const', const=True, help='Dump mesh internal details')
    parser.add_argument('--data-dir', type=str, default='.', help='where to store results')
    parser.add_argument('--runs', type=int, default=5, help='Number of runs to do')
    parser.add_argument('tests', nargs='*', default=DEFAULT_TESTS, help='specific tests to run')
    args = parser.parse_args()

    if args.v:
        log = make_reporter(DEBUG, False, sys.stderr)

    if args.mesh_details:
        os.environ['MESH_BACKGROUND_THREAD'] = '1'

    if args.latency:
        USE_MSTAT = False

    for test in args.tests:
        for i in range(args.runs):
            # shuffle configs so that results aren't artifacts of order
            shuffle(configs)
            TESTS[test](
                detailed_mesh_stats=args.mesh_details,
                enabled_configs=args.config,
                latency_stats=args.latency,
                data_dir=args.data_dir)
            # try to give the CPU a sec to cool off
            time.sleep(1)


if __name__ == '__main__':
    sys.exit(main())
